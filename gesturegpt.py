# -*- coding: utf-8 -*-
"""GestureGPT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kq0ayb8I1qhVLNoWHJi65qxCm3kDJZZm
"""

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from google.colab import drive, files
from google.colab.patches import cv2_imshow

# Mount Google Drive
drive.mount('/content/drive')

# Dataset path in Google Drive
dataset_path = '/content/drive/MyDrive/gesture'

# Image size and data lists
IMG_SIZE = 64
data = []
labels = []
classes = os.listdir(dataset_path)
class_map = {cls: idx for idx, cls in enumerate(classes)}

# Load images and labels
for label, gesture in enumerate(classes):
    gesture_path = os.path.join(dataset_path, gesture)
    for image_name in os.listdir(gesture_path):
        image_path = os.path.join(gesture_path, image_name)
        image = cv2.imread(image_path)
        if image is not None:
            image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
            image = image / 255.0
            data.append(image)
            labels.append(label)

# Convert to numpy arrays
data = np.array(data)
labels = np.array(labels)

# One-hot encode the labels
labels = to_categorical(labels, num_classes=len(classes))

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Model builder function
def build_cnn_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Define input shape and number of classes
input_shape = (IMG_SIZE, IMG_SIZE, 3)
num_classes = len(classes)
model = build_cnn_model(input_shape, num_classes)

# Model summary
model.summary()

# Training parameters
batch_size = 32
epochs = 20

# Train the model
history = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=1)

# Evaluate model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

# Predictions on the test set
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)

# Use LabelEncoder to map back to the class names for the report
label_encoder = LabelEncoder()
label_encoder.classes_ = np.array(classes)

# Generate classification report and confusion matrix with explicit labels parameter
class_report = classification_report(y_true, y_pred, labels=np.arange(len(classes)), target_names=label_encoder.classes_)
print("Classification Report:\n", class_report)

conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(len(classes)))
print("Confusion Matrix:\n", conf_matrix)

# Upload an image for prediction
uploaded = files.upload()
image_file_name = list(uploaded.keys())[0]

# Preprocess uploaded image
def preprocess_image(image_path):
    image = cv2.imread(image_path)
    if image is None:
        print("Error: Unable to read the image.")
        return None
    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))
    image = image / 255.0
    image = np.expand_dims(image, axis=0)
    return image

# Predict function for a new image
def predict_sign(image_path, model, class_names):
    processed_image = preprocess_image(image_path)
    if processed_image is None:
        return

    prediction = model.predict(processed_image)
    predicted_class_index = np.argmax(prediction)
    predicted_class_name = class_names[predicted_class_index]

    print(f'The predicted sign is: {predicted_class_name}')

    original_image = cv2.imread(image_path)
    cv2.putText(original_image, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2_imshow(original_image)

predict_sign(image_file_name, model, classes)